\documentclass[a4paper, 11pt]{article}

%Comandos para configurar el idioma
\usepackage[spanish,activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} %Necesario para el uso de las comillas latinas.
\usepackage{geometry} % Used to adjust the document margins
\usepackage[official]{eurosym}

%Importante que esta sea la última órden del preámbulo
\usepackage{hyperref}
   \hypersetup{
     pdftitle={Cuestionario de teoría 3},
     pdfauthor={Antonio Álvarez Caballero},
     unicode,
     breaklinks=true,  % so long urls are correctly broken across lines
     colorlinks=true,
     urlcolor=blue,
     linkcolor=darkorange,
     citecolor=darkgreen,
     }

   % Slightly bigger margins than the latex defaults

   \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\newcommand\fnurl[2]{%
  \href{#2}{#1}\footnote{\url{#2}}%
}


%Paquetes matemáticos
\usepackage{amsmath,amsfonts,amsthm}
\usepackage[all]{xy} %Para diagramas
\usepackage{enumerate} %Personalización de enumeraciones
\usepackage{tikz} %Dibujos
\usepackage{ dsfont }

%Tipografía escalable
\usepackage{lmodern}
%Legibilidad
\usepackage{microtype}

%Código
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\title{Cuestionario de teoría 3}
\author{Antonio Álvarez Caballero\\
    \href{mailto:analca3@correo.ugr.es}{analca3@correo.ugr.es}}
\date{\today}

\theoremstyle{definition}
\newtheorem{ejercicio}{Ejercicio}
\newtheorem{cuestion}{Cuestión}
\newtheorem*{solucion}{Solución}
\newtheorem*{bonus}{BONUS}



%%%%%%%% New sqrt
\usepackage{letltxmacro}
\makeatletter
\let\oldr@@t\r@@t
\def\r@@t#1#2{%
\setbox0=\hbox{$\oldr@@t#1{#2\,}$}\dimen0=\ht0
\advance\dimen0-0.2\ht0
\setbox2=\hbox{\vrule height\ht0 depth -\dimen0}%
{\box0\lower0.4pt\box2}}
\LetLtxMacro{\oldsqrt}{\sqrt}
\renewcommand*{\sqrt}[2][\ ]{\oldsqrt[#1]{#2} }
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%% Norm
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
%%%%%%%%%%%%%%%%%

%%%%%%%%%%% Ceil
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

  \maketitle

  \section{Cuestiones}

  \begin{cuestion}
    Considera los conjuntos de hipótesis $\mathcal{H}_1$ y $\mathcal{H}_{100}$, que contienen funciones Booleanas sobre 10 variables Booleanas, es decir $\mathcal{X} = \left\{-1,+1 \right\}^{10}$. $\mathcal{H}_1$ contiene todas las funciones Booleanas que toman valor +1 en un único punto de $\mathcal{X}$ y -1 en el resto. $\mathcal{H}_{100}$ contiene todas las funciones Booleanas que toman valor +1 exactamente en 100 puntos de $\mathcal{X}$ y -1 en el resto.

    \begin{enumerate}
      \item[a)] ¿Cuántas hipótesis contienen $\mathcal{H}_1$ y $\mathcal{H}_{100}$ ?
      \item[b)] ¿Cuántos bits son necesarios para especificar una de las hipótesis en $\mathcal{H}_1$?
      \item[c)] ¿Cuántos bits son necesarios para especificar una de las hipótesis en $\mathcal{H}_{100}$?
    \end{enumerate}

    Argumente sobre la relación entre la complejidad de una clase de funciones y la complejidad de sus componentes.
  \end{cuestion}

  \begin{solucion}
    Respondamos a cada cuestión:

    \begin{enumerate}
      \item[a)] $\mathcal{H}_1$ contiene $2^{10}$ hipótesis. Esto es porque para una función booleana con $10$ entradas, obtenemos $2^{10}=1024$ salidas. Como queremos $1$ en una entrada y $-1$ en lo demás, este número coincide con el número de posibles entradas. Para el caso $\mathcal{H}_{100}$ razonamos igual, aunque esta vez debemos coger de las $1024$ posibilidades, subconjuntos de $100$ $1$. Por tanto, este es el número combinatorio ${\binom{1024}{100}} = 7.7466\ldots \times 10^{140}$.
      \item[b)] Para especificar una de las hipótesis de $\mathcal{H}_1$ sólo nos hace falta especificar el punto donde vale $+1$, luego con $10$ bits es suficiente.
      \item[c)] Al igual que antes, necesitamos especificar dónde vale $+1$ la hipótesis. Como tenemos $100$ $+1$, necesitamos $100 \cdot 10 = 1000$ bits.
    \end{enumerate}

    La complejidad de una clase de funciones está directamente relacionada con la de sus componentes. A más complejidad en las componentes, más compleja será la clase de funciones. Le estamos dando más grados de libertad a las funciones del conjunto de hipótesis cuanto más aumentamos la complejidad de las componentes.
  \end{solucion}

  \begin{cuestion}
    Suponga que durante 5 semanas seguidas, recibe un correo postal que predice el resultado del partido de fútbol del domingo, donde hay apuestas sustanciosas. Cada lunes revisa la predicción y observa que la predicción es correcta en todas las ocasiones. El día de después del quinto partido recibe una carta diciéndole que si desea conocer la predicción de la semana que viene debe pagar 50.000\euro{}. ¿Pagaría?

    \begin{enumerate}
      \item[a)] ¿Cuántas son las posibles predicciones gana-pierde para los cinco partidos?
      \item[b)] Si el remitente desea estar seguro de que al menos una persona recibe de él la precicción correcta sobre los 5 partidos, ¿Cuál es el mínimo número de cartas que deberá de enviar?
      \item[c)] Después de la primera carta prediciendo el resultado del primer partido, ¿A cuántos de los seleccionados inicialmente deberá enviarle la segunda carta?
      \item[d)] ¿Cuántas cartas en total se habrán enviado después de las primeras cinco semanas?
      \item[e)] Si el coste de imprimir y enviar las cartas es de 0.5€ por carta, ¿Cuánto ingresa el remitente si el receptor de las 5 predicciones acertadas decide pagar los 50.000\euro{}?
      \item[f)] ¿Puede relacionar esta situación con la función de crecimiento y la credibilidad del ajuste de los datos?
    \end{enumerate}
  \end{cuestion}

  \begin{solucion}
    Veamos cada una.

    \begin{enumerate}
      \item[a)] Suponiendo que los partidos no pueden empatar, las posibles predicciones gana-pierde son claramente $2^5=32$ posibilidades.
      \item[b)] Al ser un problema binario, el número mínimo de cartas a enviar es $\sum_{i=1}^5 2^i$. Esto es porque la primera semana se deben enviar $2^5=32$ cartas, la mitad de ellas con una posibilidad (gana A) y la otra mitad con la otra (gana B). La siguiente semana sólo la mitad de ellos tendrán la predicción correcta, luego hay que enviar $2^4=16$ cartas a los que obtuvieron la predicción correcta, igualmente con mitad y mitad. Así hasta la 5º semana, que sólo habrá que enviar $2^1=2$ cartas, asegurando a una persona haber recibido 5 predicciones correctas.
      \item[c)] Como se ha explicado antes, hay que enviarle cartas a las personas que hayan recibido la predicción correcta. En el caso anterior, para asegurarnos que una persona reciba después de 5 semanas las predicciones correctas, hay que enviar cartas a la mitad de personas, $2^4=16$.
      \item[d)] En total se mandan $\sum_{i=1}^5 2^i = 62$
      \item[e)] Se habría gastado 31\euro{} y habría ganado 50.000\euro{}, luego el beneficio sería de 49.969\euro{}.
    \end{enumerate}
  \end{solucion}

  \begin{cuestion}
    En un experimento para determinar la distribución del tamaño de los peces en un lago, se decide echar una red para capturar una muestra representativa. Así se hace y se obtiene una muestra suficientemente grande de la que se pueden obtener conclusiones estadísticas sobre los peces del lago. Se obtiene la distribución de peces por tamaño y se entregan las conclusiones. Discuta si las conclusiones obtenidas servirán para el objetivo que se persigue e identifique si hay algo que lo impida.
  \end{cuestion}

  \begin{solucion}
    El objetivo no tiene por qué conseguirse, porque a priori no sabemos si la muestra es realmente representativa. Si la distribución de tamaño de los peces del lago no coincide con la distribución que sigue la muestra, el objetivo no se cumplirá, porque hemos estado tomando una muestra sesgada de la población de peces. Factores como la época del año, el tamaño y forma de la red o el lugar donde se realiza la prueba son idóneos para sesgar la muestra.
  \end{solucion}

  \begin{cuestion}
    Considere la siguiente aproximación al aprendizaje. Mirando los datos, parece que los datos son linealmente separables, por tanto decidimos usar un simple perceptrón y obtenemos un error de entrenamiento cero con los pesos óptimos encontrados. Ahora deseamos obtener algunas conclusiones sobre generalización, por tanto miramos el valor $d_{VC}$ de nuestro modelo y vemos que es $d+1$. Usamos dicho valor de $d_{VC}$ para obtener una cota del error de test. Argumente a favor o en contra de esta forma de proceder identificando los posibles fallos si los hubiera y en su caso cuál hubiera sido la forma correcta de actuación.
  \end{cuestion}

  \begin{solucion}
    El principal problema es que hemos visto los datos. Al haber visto los datos ya tenemos información del problema, lo cual sesga el conocimiento que podemos aprender de ellos. Así se pierde la capacidad de generalización del modelo.

    El tema de la cota pierde totalmente su validez al haber contaminado el aprendizaje, luego esa cota tampoco será real.

    Una forma correcta de actuar sería tomar un modelo, analizar sus errores dentro de la muestra y de test y ya con la $d_{VC}$ calcularíamos una cota del error de generalización. Esto aplicado a varios modelos podrá darnos una estimación más fiable del modelo más apropiado para este problema.
  \end{solucion}

  \begin{cuestion}
    Suponga que separamos 100 ejemplos de un conjunto $\mathcal{D}$ que no serán usados para entrenamiento, sino que serán usados para seleccionar una de las tres hipótesis finales $g_1,g_2,g_3$ producidas por tres algoritmos de aprendizaje distintos entrenados sobre el resto de datos. Cada algoritmo trabaja con un conjunto $\mathcal{H}$ de tamaño $500$. Nuestro deseo es caracterizar la precisión de la estimación $E_{out}(g)$ sobre la hipótesis final seleccionada cuando usamos los mismos 100 ejemplos para hacer la estimación.

    \begin{enumerate}
      \item[a)] ¿Qué expresión usaría para calcular la precisión? Justifique la decisión.
      \item[b)] ¿Cuál es el nivel de contaminación de estos 100 ejemplos comparándolo con el caso donde estas muestras fueran usadas en el entrenamiento en lugar de en la selección final?
    \end{enumerate}
  \end{cuestion}

  \begin{solucion}
    Resolvemos por partes.
    \begin{enumerate}
      \item[a)] Como el conjunto $\mathcal{H}$ es finito, la expresión que debemos utilizar para estimar $E_{out}$ es la desigualdad de Hoeffding. Lo único que tenemos que ajustar es $|\mathcal{H}|$. Es claro que $|\mathcal{H}| = \sum_{i=1}^3 |\mathcal{H}_i| = 1500$, ya que las tres funciones han sido propuestas por los propios algoritmos de aprendizaje.
      \item[b)] La contaminación es mayor si elegimos la función hipótesis en base a estos 100 ejemplos, ya que dependerá en mayor medida de estos 100 ejemplos. Si hubiéramos dejado dentro estos 100 elementos, habrán tenido peso en la elección de una hipótesis, o incluso contaminaríamos el aprendizaje como en el ejercicio anterior (el modelo conoce los datos), pero posiblemente esta contaminación sea más indirecta.
    \end{enumerate}


  \end{solucion}

  \begin{cuestion}
    Considere la tarea de seleccionar una regla del vecino más cercano. ¿Qué hay de erróneo en la siguiente lógica que se aplica a la selección de $k$? (Los límites son cuando $N \rightarrow \infty$).
    Considere la posibilidad de establecer la clase de hipótesis $\mathcal{H}_{NN}$ con N reglas, las k-NN hipótesis, usando $k=1,\ldots,N$. Use el error dentro de la muestra para elegir un valor de $k$ que minimiza $E_{in}$. Utilizando el error de generalización para N hipótesis, obtenemos la conclusión de que $E_{in} \rightarrow E_{out}$ porque $\frac{\log(N)}{N} \rightarrow 0$. Por lo tanto concluimos que asintóticamente, estaremos eligiendo el mejor valor de $k$, basándonos sólo en $E_{in}$.
  \end{cuestion}

  \begin{solucion}
    Es claro que el $k$ elegido sería $k=1$, ya que para dicho $k$ y tomando los datos dentro de la muestra, $E_{in}=0$. Sabemos que $k=1$ no es el mejor valor para el k-NN, por lo que esta lógica para elegir $k$ no es la adecuada. Sería más adecuado tomar $k=\sqrt{N}$ o bien utilizar validación cruzada.
  \end{solucion}

  \begin{cuestion}
    Responder estas cuestiones:
    \begin{enumerate}
      \item[a)] Considere un núcleo Gaussiano en un modelo de base radial. ¿Qué representa $g(x)$ (ecuación 6.2 del libro LfD) cuando $||x|| \rightarrow \infty$ para el modelo RBF no-paramétrico vs el modelo RBF paramétrico, asumiendo $w_n$ fijos?
      \item[b)] Sea $\mathcal{Z}$ una matriz cuadrada de características definida por $\mathcal{Z}_{nj}=\Phi_j(x_n)$, donde $\Phi_j(x)$ representa una transformación no lineal. Suponer que $\mathcal{Z}$ es invertible. Mostrar que un modelo paramétrico de base radial, con $g(x) = w^T\Phi(x)$ y $ w = \mathcal{Z}^{-1}y $, interpola los puntos de forma exacta. Es decir, que $g(x_n) = y_n$, con $E_{in}(g) = 0$.
      \item[c)] ¿Se verifica siempre que $E_{in}(g) = 0$ en el modelo no paramétrico?
    \end{enumerate}
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    Verificar que la función $sign$ puede ser aproximada por la función $tanh$. Dado $w_1$ y $\epsilon > 0$ encontrar $w_2$ tal que $|sign(x_n^Tw_1) - tanh(x_n^Tw_2)| \leq \epsilon$ para $x_n \in \mathcal{D}$. Ayuda: Analizar la función $tanh(\alpha x), \alpha \in \mathbb{R}$.
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    Sea V y Q el número de nodos y pesos en una red neuronal,

    $$ V = \sum_{l=0}^L d^{(l)}, \; \; Q = \sum_{l=1}^L d^{(l)} \left( d^{(l+1)} + 1\right) $$

    En términos de V y Q, ¿Cuántas operaciones se realizan en un pase hacia adelante (sumas, multiplicaciones, y evaluaciones de $\theta$)? Ayuda: Analizar la complejidad en términos de V y de Q.



  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    Para el perceptrón sigmoidal $h(x) = tanh(x^Tw)$, sea el error de ajuste $E_{in}(w) = \frac{1}{N}\sum_{n=1}^N \left( tanh(x_n^Tw) - y_n \right)^2$. Mostrar que

    $$ \nabla E_{in}(w) = \frac{2}{N} \sum_{n=1}^N \left( tanh(x_n^Tw) - y_n \right) \left( 1 - tanh(x_n^Tw)^2 \right) x_n $$

    Si $w \rightarrow \infty$, ¿Qué le sucede al gradiente? ¿Cómo se relaciona esto con la dificultad de optimizar el perceptrón multicapa?

  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

\end{document}
