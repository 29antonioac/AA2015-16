\documentclass[a4paper, 11pt]{article}

%Comandos para configurar el idioma
\usepackage[spanish,activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} %Necesario para el uso de las comillas latinas.
\usepackage{geometry} % Used to adjust the document margins

%Importante que esta sea la última órden del preámbulo
\usepackage{hyperref}
   \hypersetup{
     pdftitle={Cuestionario de teoría 3},
     pdfauthor={Antonio Álvarez Caballero},
     unicode,
     breaklinks=true,  % so long urls are correctly broken across lines
     colorlinks=true,
     urlcolor=blue,
     linkcolor=darkorange,
     citecolor=darkgreen,
     }

   % Slightly bigger margins than the latex defaults

   \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\newcommand\fnurl[2]{%
  \href{#2}{#1}\footnote{\url{#2}}%
}


%Paquetes matemáticos
\usepackage{amsmath,amsfonts,amsthm}
\usepackage[all]{xy} %Para diagramas
\usepackage{enumerate} %Personalización de enumeraciones
\usepackage{tikz} %Dibujos
\usepackage{ dsfont }

%Tipografía escalable
\usepackage{lmodern}
%Legibilidad
\usepackage{microtype}

%Código
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\title{Cuestionario de teoría 3}
\author{Antonio Álvarez Caballero\\
    \href{mailto:analca3@correo.ugr.es}{analca3@correo.ugr.es}}
\date{\today}

\theoremstyle{definition}
\newtheorem{ejercicio}{Ejercicio}
\newtheorem{cuestion}{Cuestión}
\newtheorem*{solucion}{Solución}
\newtheorem*{bonus}{BONUS}



%%%%%%%% New sqrt
\usepackage{letltxmacro}
\makeatletter
\let\oldr@@t\r@@t
\def\r@@t#1#2{%
\setbox0=\hbox{$\oldr@@t#1{#2\,}$}\dimen0=\ht0
\advance\dimen0-0.2\ht0
\setbox2=\hbox{\vrule height\ht0 depth -\dimen0}%
{\box0\lower0.4pt\box2}}
\LetLtxMacro{\oldsqrt}{\sqrt}
\renewcommand*{\sqrt}[2][\ ]{\oldsqrt[#1]{#2} }
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%% Norm
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
%%%%%%%%%%%%%%%%%

%%%%%%%%%%% Ceil
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

  \maketitle

  \section{Cuestiones}

  \begin{cuestion}
    cuestiond
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    cuestion
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    cuestion
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    cuestion
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    cuestion
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    cuestion
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    cuestion
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    cuestion
  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    Sea V y Q el número de nodos y pesos en una red neuronal,

    $$ V = \sum_{l=0}^L d^{(l)}, \; \; Q = \sum_{l=1}^L d^{(l)} \left( d^{(l+1)} + 1\right) $$

    En términos de V y Q, ¿Cuántas operaciones se realizan en un pase hacia adelante (sumas, multiplicaciones, y evaluaciones de $\theta$)? Ayuda: Analizar la complejidad en términos de V y de Q.



  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}

  \begin{cuestion}
    Para el perceptrón sigmoidal $h(x) = tanh(x^Tw)$, sea el error de ajuste $E_{in}(w) = \frac{1}{N}\sum_{n=1}^N \left( tanh(x_n^Tw) - y_n \right)^2$. Mostrar que

    $$ \nabla E_{in}(w) = \frac{2}{N} \sum_{n=1}^N \left( tanh(x_n^Tw) - y_n \right) \left( 1 - tanh(x_n^Tw)^2 \right) x_n $$

    Si $w \rightarrow \infty$, ¿Qué le sucede al gradiente? ¿Cómo se relaciona esto con la dificultad de optimizar el perceptrón multicapa?

  \end{cuestion}

  \begin{solucion}
    solucion
  \end{solucion}
































\end{document}
