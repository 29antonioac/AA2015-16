---
title: "Trabajo 3"
author: "Antonio Álvarez Caballero"
date: "27 de mayo de 2016"
output: pdf_document
---

```{r setup, include=FALSE}
require(ISLR)
require(ggplot2)
require(plotly)
require(reshape)
require(GGally)
require(ROCR)
require(MESS)
require(boot)
require(MASS)
require(glmnet)
require(e1071)
require(caret)
require(knitr)

set.seed(123456789)
knitr::opts_chunk$set(echo = TRUE)
```

# Ejercicio 1

```{r Auto, include = FALSE}
attach(Auto)
pairs(Auto)
```

## Apartado a)

Parece ser que las variables de las que más depende _mpg_ son _displacement_, _horsepower_ y _weight_. Veámoslas con más detalle.

```{r plots, echo = FALSE, cache = TRUE}
ggpairs(Auto, columns =  c("mpg","displacement", "horsepower", "weight"))
# ggplot(Auto, aes(x=cylinders,y=mpg)) + geom_boxplot(aes(group = cut_width(cylinders,0.25)))
ggplot(Auto, aes(x=displacement,y=mpg)) + geom_boxplot(aes(group = cut_width(displacement,0.25)))
ggplot(Auto, aes(x=horsepower,y=mpg)) + geom_boxplot(aes(group = cut_width(horsepower,0.25)))
ggplot(Auto, aes(x=weight,y=mpg)) + geom_boxplot(aes(group = cut_width(weight,0.25)))
# ggplot(Auto, aes(x=acceleration,y=mpg)) + geom_boxplot(aes(group = cut_width(acceleration,0.25)))
# ggplot(Auto, aes(x=year,y=mpg)) + geom_boxplot(aes(group = cut_width(year,0.25)))
# ggplot(Auto, aes(x=origin,y=mpg)) + geom_boxplot(aes(group = cut_width(origin,0.25)))
# ggplot(Auto, aes(x=name,y=mpg)) + geom_boxplot(aes(group = cut_width(name,0.25)))
```

## Apartado b)

Seleccionamos las variables que hemos decidido para predecir.

```{r selection}
Auto.selected <- Auto[,c("displacement","horsepower","weight")]
```

## Apartado c)

Como nuestro conjunto de datos es grande (```r I(nrow(Auto))``` instancias), podemos realizar un muestreo aleatorio. Así tampoco falseamos las muestras, cosa que podría pasarnos si realizamos un muestreo estratificado.

```{r split}
index <- sample(nrow(Auto), size = 0.8*nrow(Auto) )

Auto.train <- Auto.selected[index,]
Auto.test <- Auto.selected[-index,]
```

## Apartado d)

Vamos a crear una nueva variable, _mpg01_, la cual tendrá 1 si el valor de _mpg_ está por encima de la mediana y -1 en otro caso.

```{r mpg01}
mpg01 <- ifelse(Auto$mpg >= median(Auto$mpg), 1, 0)
Auto.selected$mpg01 <- mpg01
Auto.train$mpg01 <- mpg01[index]
Auto.test$mpg01 <- mpg01[-index]
```

### Apartado d1)

Vamos a ajustar un modelo de regresión logística para predecir _mpg01_.

```{r regLog}
model.LogReg <- glm(mpg01 ~ ., data = Auto.train, family = binomial)
prediction.LogReg <- predict(model.LogReg, newdata = Auto.test)
prediction.LogReg
error.test <- "¿Esto cómo va?"
```

El error de test de este modelo es ```r I(error.test)```.

### Apartado d2)

Ahora vamos a ajusart un modelo k-NN.

```{r kNN}

```

### Apartado d3)

Veamos las curvas ROC de ambos modelos.


```{r ROC}
roc.prediction.regLog <- prediction(prediction.LogReg, Auto.test$mpg01)
roc.performance.regLog <- performance(roc.prediction.regLog, measure = "tpr", x.measure = "fpr")

### Meter del knn

####
roc.performance.knn <- roc.performance.regLog

roc.data <- data.frame(x  = roc.performance.regLog@x.values[[1]],
                       y1 = roc.performance.regLog@y.values[[1]],
                       y2 = roc.performance.knn@y.values[[1]])

ggplot(roc.data, aes(x)) + 
  geom_line(aes(y = y1, colour = "Logistic Regression")) +
  geom_line(aes(y = y2, colour = "k-NN")) +
  theme(legend.title = element_blank()) + 
  labs(title= "ROC curves", x = "False positive rate", y = "True positive rate")

auc.regLog  <- auc(roc.data$x,roc.data$y1, type = 'spline')
auc.knn     <- auc(roc.data$x,roc.data$y2, type = 'spline')
```

El área bajo la curva de la ROC de regresión logística es ```r I(auc.regLog)``` y la del k-NN es ```r I(auc.knn)```. Luego ```r if(auc.regLog > auc.knn) "regresión logística" else "k-NN"``` es el modelo que mejor _performance_ tiene.

## Apartado e) (Bonus-1)

Para estudiar el error con validación cruzada hacemos uso de `cv.glm`

```{r cv.glm}
model.full.LogReg <- glm(mpg01 ~ ., data = Auto.selected)
cv.LogReg <- cv.glm(data = Auto.selected, glmfit = model.full.LogReg, K = 5)
cv.LogReg$delta
```

El error estimado es el primero de este vector. El segundo es un ajusto para compenar el sesgo introducido al no usar *Leave-One-Out*.

Para el caso del k-NN

```{r cv.knn}

```

Por tanto, vemos que es mejor _uno_.

## Apartado f) (Bonus-2)

Por hacer

# Ejercicio 2

## Apartado a)

Ajustamos con validación cruzada sobre la variable _crim_, que es la que está en la posición 1.

```{r boston}
attach(Boston)

index <- sample(nrow(Boston), 0.8*nrow(Boston))
Boston.full <- Boston
Boston.train <- Boston[index,]
Boston.test <- Boston[-index,]

model.Boston <- glmnet(as.matrix(Boston.train[,-1]),Boston.train[,1], alpha = 1)

```


## Apartado b)

Ahora utilizamos un método LASSO y seleccionamos las variables que están por encima de un umbral.

```{r LASSO}
cv.Boston <- cv.glmnet(as.matrix(Boston[,-1]), Boston[,1], nfolds = 5, alpha = 1)
lasso.coeff <- predict(cv.Boston, type="coefficients", s = cv.Boston$lambda.min)
threshold <- 0.1
selected <- which(abs(lasso.coeff) > threshold)[-1]
```

Con esto afirmamos que las características que superan nuestro umbral ```r I(threshold)``` son ```r I(selected)```.

Seguir con regularización.

## Apartado c)

Al igual que en el anterior apartado, definimos una nueva variable usando la mediana como umbral.

```{r crim1}
crim1 <- ifelse(Boston$crim > median(Boston$crim), 1, -1)
Boston.full$crim1 <- crim1
Boston.train <- Boston.full[index,]
Boston.test <- Boston.full[-index,]
```

Ahora ajustamos varias _SVM_, probaremos la lineal y con los núcleos disponibles, y veremos cómo se comporta cada uno.
'Ver cuál sería mejor a priori con pairs o similar'.

```{r SVM}
svm.linear <- svm(crim1 ~ ., data = Boston.train[,-1], kernel = "linear")
svm.linear.prediction <- predict(svm.linear, newdata = Boston.test[,-1])
# confusionMatrix(svm.linear.prediction, Boston.test$crim1)
svm.linear.prediction

svm.polynomial <- svm(crim1 ~ ., data = Boston.train[,-1], kernel = "polynomial")
svm.polynomial.prediction <- predict(svm.polynomial, newdata = Boston.test[,-1])
# confusionMatrix(svm.polynomial.prediction, Boston.test$crim1)
svm.polynomial.prediction

svm.radial <- svm(crim1 ~ ., data = Boston.train[,-1], kernel = "radial")
svm.radial.prediction <- predict(svm.radial, newdata = Boston.test[,-1])
# confusionMatrix(svm.radial.prediction, Boston.test$crim1)
svm.radial.prediction

svm.sigmoid <- svm(crim1 ~ ., data = Boston.train[,-1], kernel = "sigmoid")
svm.sigmoid.prediction <- predict(svm.sigmoid, newdata = Boston.test[,-1])
# confusionMatrix(svm.sigmoid.prediction, Boston.test$crim1)
svm.sigmoid.prediction
```

Analizar el error.

## Apartado d) (Bonus-3)

Ajustamos con validación cruzada sobre la variable _crim_.

```{r cvBoston, eval=F}

cv.Boston <- cv.glmnet(as.matrix(Boston[,-1]), Boston[,1], nfolds = 5, alpha = 1)
```

El error de validación cruzada (respondiendo al Bonus-3) es 

```{r}
cv.Boston$cvm
```

Completar solución.